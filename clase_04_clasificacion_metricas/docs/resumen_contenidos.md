En esta clase dimos un paso clave dentro del recorrido de aprendizaje supervisado. Mientras que en clases anteriores exploramos modelos lineales como la regresión y la regresión logística, hoy ampliamos el repertorio con algoritmos que nos permiten capturar relaciones más complejas en los datos, sin perder de vista la necesidad de interpretar y evaluar cada decisión que toman.

Aprendimos que:

KNN clasifica por similitud, sin entrenar reglas, y nos permite ver cómo cambia la frontera de decisión según el vecindario local.

Los árboles de decisión generan estructuras jerárquicas de reglas comprensibles, ideales para comunicar modelos a equipos no técnicos.

SVM encuentra la mejor separación posible entre clases, maximizando el margen, y puede adaptarse a fronteras no lineales con el truco del kernel.

Por último, entendimos que medir el rendimiento del modelo va mucho más allá del accuracy, y que métricas como precisión, recall, F1-score y AUC son fundamentales cuando las clases están desbalanceadas y no todos los errores tienen el mismo impacto.

Ahora nos toca seguir practicando con estos modelos y aprender a elegir cuál usar según el problema, los datos y los objetivos del proyecto. Porque más allá del algoritmo, lo que realmente marca la diferencia es saber qué queremos resolver y cómo evaluar si lo estamos logrando.