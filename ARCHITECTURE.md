# ğŸ—ï¸ Arquitectura del Proyecto
## Estructura y OrganizaciÃ³n del Curso de Data Science

**Ãšltima actualizaciÃ³n**: Febrero 2026  
**VersiÃ³n**: 1.0.0

---

## ğŸ“‹ VisiÃ³n General

El proyecto estÃ¡ organizado para facilitar el aprendizaje progresivo de conceptos de Data Science, desde fundamentos de Machine Learning hasta tÃ©cnicas avanzadas de Deep Learning.

**Principios de diseÃ±o:**
- âœ… **Modularidad**: Cada clase es independiente pero progresiva
- âœ… **Consistencia**: Estructura similar en todas las clases
- âœ… **Practicidad**: Casos reales de negocio
- âœ… **Reproducibilidad**: Seeds fijas, documentaciÃ³n exhaustiva

---

## ğŸ—‚ï¸ Estructura de Directorios REAL

**Nota**: Esta estructura refleja el estado ACTUAL del proyecto post-limpieza (Febrero 2026).

```
data_science_henry/
â”‚
â”œâ”€â”€ clase_01_introduccion_ml/
â”‚   â”œâ”€â”€ notebooks/                  # 3 notebooks
â”‚   â”‚   â”œâ”€â”€ resumen_actividad_clase_01.ipynb
â”‚   â”‚   â”œâ”€â”€ actividad_clase_01_eda_retailboost.ipynb
â”‚   â”‚   â””â”€â”€ 02_homework_eda_retailboost.ipynb
â”‚   â”œâ”€â”€ scripts/                    # 2 scripts (ÃšNICA clase con scripts)
â”‚   â”‚   â”œâ”€â”€ preprocessing.py        # Funciones de preprocesamiento
â”‚   â”‚   â””â”€â”€ data_loader.py          # Carga de datos
â”‚   â”œâ”€â”€ docs/                       # 3 documentos
â”‚   â”‚   â”œâ”€â”€ actividad_clase.md
â”‚   â”‚   â”œâ”€â”€ resumen_contenidos.md
â”‚   â”‚   â””â”€â”€ homework.md
â”‚   â”œâ”€â”€ data/                       # 5 datasets
â”‚   â”‚   â”œâ”€â”€ retailboost_customers.csv
â”‚   â”‚   â”œâ”€â”€ retailboost_customers_processed.csv
â”‚   â”‚   â”œâ”€â”€ retailboost_customers_procesado.csv
â”‚   â”‚   â””â”€â”€ retailboost_customers_final.csv
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ clase_02_regresion/
â”‚   â”œâ”€â”€ notebooks/                  # 3 notebooks
â”‚   â”œâ”€â”€ scripts/                    # 1 script
â”‚   â”‚   â””â”€â”€ get_metrics.py          # MÃ©tricas de regresiÃ³n
â”‚   â”œâ”€â”€ docs/                       # 3 documentos
â”‚   â”œâ”€â”€ data/                       # 1 dataset
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ clase_03_regresion_logistica/
â”‚   â”œâ”€â”€ notebooks/                  # 2 notebooks
â”‚   â”œâ”€â”€ docs/                       # 4 documentos
â”‚   â”œâ”€â”€ data/                       # 1 dataset
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ clase_04_clasificacion_metricas/
â”‚   â”œâ”€â”€ notebooks/                  # 1 notebook
â”‚   â”œâ”€â”€ docs/                       # 2 documentos
â”‚   â””â”€â”€ data/                       # 1 dataset
â”‚
â”œâ”€â”€ clase_05_modelos_ensamble/
â”‚   â”œâ”€â”€ notebooks/                  # 1 notebook
â”‚   â””â”€â”€ docs/                       # 2 documentos
â”‚
â”œâ”€â”€ clase_06_optimizacion_modelos/
â”‚   â”œâ”€â”€ notebooks/                  # 3 notebooks
â”‚   â”‚   â”œâ”€â”€ 2_GradientBoosting_Optimizacion.ipynb
â”‚   â”‚   â”œâ”€â”€ 2_GradientBoosting_Optimizacion_RESUMEN.ipynb
â”‚   â”‚   â””â”€â”€ catboost_info/          # Subdirectorio auxiliar
â”‚   â””â”€â”€ docs/                       # 2 documentos
â”‚
â”œâ”€â”€ clase_07_aprendizaje_no_supervisado_i/
â”‚   â”œâ”€â”€ notebooks/                  # 2 notebooks
â”‚   â”œâ”€â”€ docs/                       # 2 documentos
â”‚   â””â”€â”€ data/                       # 3 datasets
â”‚
â”œâ”€â”€ clase_08_aprendizaje_no_supervisado_ii/
â”‚   â”œâ”€â”€ notebooks/                  # 2 notebooks + 1 markdown
â”‚   â”œâ”€â”€ docs/                       # 2 documentos
â”‚   â””â”€â”€ data/                       # 4 datasets
â”‚
â”œâ”€â”€ clase_09_series_temporales/
â”‚   â”œâ”€â”€ notebooks/                  # 2 notebooks
â”‚   â”œâ”€â”€ docs/                       # 4 documentos
â”‚   â””â”€â”€ data/                       # 1 dataset
â”‚
â”œâ”€â”€ clase_10_deep_learning/ â­       # CLASE MÃS COMPLETA
â”‚   â”œâ”€â”€ notebooks/                  # 4 notebooks + 2 markdown guÃ­as
â”‚   â”‚   â”œâ”€â”€ homework_vix_lstm_completo_didactico.ipynb â­
â”‚   â”‚   â”œâ”€â”€ econotrend_lstm_forecast.ipynb
â”‚   â”‚   â”œâ”€â”€ finshield_pytorch_dense_Edited_Leo2.ipynb
â”‚   â”‚   â”œâ”€â”€ LECTURAS_COMPLETAS_POR_CELDA.md
â”‚   â”‚   â””â”€â”€ CORRECCIONES.md
â”‚   â”œâ”€â”€ docs/                       # 7 documentos
â”‚   â”‚   â”œâ”€â”€ homework.md
â”‚   â”‚   â”œâ”€â”€ resumen_contenidos.md
â”‚   â”‚   â”œâ”€â”€ ANALISIS_COMPLETO_VIX_LSTM.md
â”‚   â”‚   â”œâ”€â”€ LECTURAS_RECOMENDADAS_VIX_LSTM.md
â”‚   â”‚   â”œâ”€â”€ VERIFICACION_AFIRMACIONES_DATOS.md
â”‚   â”‚   â”œâ”€â”€ INDICE_RAPIDO.md
â”‚   â”‚   â””â”€â”€ README_ANALISIS_COMPLETO.md
â”‚   â”œâ”€â”€ data/                       # 2 datasets
â”‚   â”‚   â”œâ”€â”€ econotrend_vix_sim.csv
â”‚   â”‚   â””â”€â”€ finshield_transactions_clean.csv
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ clase_11_consulta/               # A COMPLETAR
â”‚   â”œâ”€â”€ notebooks/                  # Resumen de todo el curso
â”‚   â”œâ”€â”€ data/                       # Resumen de datasets y casos
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ utils/                          # Utilidades compartidas
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_processing.py
â”‚   â”œâ”€â”€ visualization.py
â”‚   â””â”€â”€ model_evaluation.py
â”‚
â”œâ”€â”€ tests/                          # Tests unitarios
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ test_*.py
â”‚
â”œâ”€â”€ docs/                           # DocumentaciÃ³n general
â”‚   â””â”€â”€ (vacÃ­o por ahora)
â”‚
â”œâ”€â”€ .venv/                          # Entorno virtual (auto-generado)
â”œâ”€â”€ .git/                           # Control de versiones
â”œâ”€â”€ .gitignore                      # Archivos ignorados
â”œâ”€â”€ .env.example                    # Template de variables
â”œâ”€â”€ .claude/                        # ConfiguraciÃ³n de Claude (AI)
â”‚
â”œâ”€â”€ README.md                       # DocumentaciÃ³n principal
â”œâ”€â”€ QUICKSTART.md                   # GuÃ­a de inicio rÃ¡pido
â”œâ”€â”€ ARCHITECTURE.md                 # Este archivo
â”œâ”€â”€ CONTRIBUTING.md                 # GuÃ­a de contribuciÃ³n
â”œâ”€â”€ LICENSE                         # Licencia MIT
â”œâ”€â”€ Makefile                        # Comandos automatizados
â”œâ”€â”€ pyproject.toml                  # Poetry config
â”œâ”€â”€ poetry.lock                     # Lock file de dependencias
â”œâ”€â”€ requirements.txt                # Backup para pip
â””â”€â”€ setup.py                        # InstalaciÃ³n como paquete
```

---

## ğŸ“Š EstadÃ­sticas Actuales

| MÃ©trica | Cantidad |
|---------|----------|
| **Total de clases** | 11 |
| **Notebooks** | 23 |
| **Datasets Ãºnicos** | 20 |
| **Documentos** | 31 |
| **Scripts Python** | 3 (clase_01, clase_02) |
| **LÃ­neas de cÃ³digo** | ~15,000 (notebooks) |
| **TamaÃ±o total** | ~50 MB (sin .venv) |

---

## ğŸ¯ Convenciones y EstÃ¡ndares

### Nombres de Archivos

**Notebooks:**
- Formato: `[numero]_[nombre_descriptivo].ipynb`
- Ejemplos: 
  - `01_exploratory_data_analysis.ipynb`
  - `homework_clasificacion_leads.ipynb`
  - `actividad_clase_03_regresion_logistica.ipynb`

**Scripts:**
- Formato: `snake_case.py`
- Ejemplos: `data_loader.py`, `get_metrics.py`, `preprocessing.py`

**Documentos:**
- Formato: `snake_case.md` o `nombre_descriptivo.md`
- Ejemplos: `homework.md`, `resumen_contenidos.md`, `temas_clase.md`

**Datasets:**
- Formato: `[proyecto]_[entidad]_[estado].csv`
- Ejemplos: 
  - `retailboost_customers.csv` (raw)
  - `retailboost_customers_processed.csv` (procesado)
  - `finshield_transactions_clean.csv` (limpio)

### OrganizaciÃ³n de Notebooks

**Estructura estÃ¡ndar:**

1. **TÃ­tulo y Contexto** (Markdown)
2. **Tabla de contenidos** (con anclas)
3. **ImportaciÃ³n de librerÃ­as** (CÃ³digo)
4. **ConfiguraciÃ³n** (seeds, parÃ¡metros)
5. **Carga de datos** (CÃ³digo)
6. **EDA** (CÃ³digo + visualizaciones)
7. **Preprocesamiento** (CÃ³digo)
8. **Modelado** (CÃ³digo)
9. **EvaluaciÃ³n** (CÃ³digo + mÃ©tricas)
10. **Conclusiones** (Markdown)

**Best practices:**
- Celdas de cÃ³digo cortas (<50 lÃ­neas)
- Comentarios explicativos
- Outputs limpios y relevantes
- Visualizaciones con tÃ­tulos y labels
- Seeds fijas para reproducibilidad

---

## ğŸ”„ Flujo de Trabajo

### Para Estudiantes

```mermaid
graph LR
    A[Leer README de la clase] --> B[Estudiar docs/]
    B --> C[Ejecutar notebooks/]
    C --> D[Experimentar]
    D --> E[Resolver homework]
    E --> F[Avanzar siguiente clase]
```

**Pasos detallados:**

1. **PreparaciÃ³n** (10 min):
   - Leer README.md de la clase
   - Revisar `resumen_contenidos.md` en docs/

2. **TeorÃ­a** (30 min):
   - Estudiar material teÃ³rico en docs/
   - Revisar referencias externas

3. **PrÃ¡ctica** (90 min):
   - Ejecutar notebooks paso a paso
   - Leer comentarios y explicaciones

4. **ExperimentaciÃ³n** (30 min):
   - Modificar parÃ¡metros
   - Probar diferentes enfoques
   - Visualizar resultados

5. **Homework** (60 min):
   - Resolver ejercicios propuestos
   - Documentar decisiones

### Para Instructores

```mermaid
graph LR
    A[Crear notebooks] --> B[Documentar en docs/]
    B --> C[Preparar datasets]
    C --> D[Testear cÃ³digo]
    D --> E[Actualizar README]
    E --> F[Revisar con estudiantes]
```

**Checklist antes de cada clase:**

- [ ] Notebooks ejecutan sin errores
- [ ] Outputs limpiados (para Git)
- [ ] Seeds fijas (reproducibilidad)
- [ ] DocumentaciÃ³n actualizada
- [ ] Datasets disponibles en data/
- [ ] README de la clase completo
- [ ] Homework claramente definido

---

## ğŸ› ï¸ GestiÃ³n de Dependencias

### Con Poetry (Recomendado)

```bash
# Agregar librerÃ­a
poetry add nombre-libreria

# Agregar con versiÃ³n especÃ­fica
poetry add "numpy>=1.26.0,<2.0.0"

# Agregar para desarrollo (no producciÃ³n)
poetry add --group dev pytest-cov

# Actualizar todas las dependencias
poetry update

# Ver Ã¡rbol de dependencias
poetry show --tree

# Exportar a requirements.txt
poetry export -f requirements.txt --output requirements.txt
```

### Grupos de Dependencias

**En `pyproject.toml`:**

```toml
[tool.poetry.dependencies]
python = "^3.9"
numpy = "^1.26.4"
pandas = "^2.3.3"
...

[tool.poetry.group.dev.dependencies]
pytest = "^8.0.0"
black = "^24.0.0"
...
```

---

## ğŸ§ª Testing y Calidad

### Estructura de Tests

```
tests/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ conftest.py                    # Fixtures compartidas
â”œâ”€â”€ test_data_processing.py        # Tests de utils/data_processing.py
â”œâ”€â”€ test_visualization.py          # Tests de utils/visualization.py
â””â”€â”€ test_model_evaluation.py       # Tests de utils/model_evaluation.py
```

### Ejecutar Tests

```bash
# Todos los tests
make test
# o
poetry run pytest

# Con cobertura
poetry run pytest --cov=utils --cov-report=html

# Test especÃ­fico
poetry run pytest tests/test_data_processing.py -v

# Con output verbose
poetry run pytest -vv
```

---

## ğŸ”Œ Utilidades Compartidas (utils/)

MÃ³dulo de Python con funciones reutilizables entre clases.

### `data_processing.py`
```python
def load_data(path, **kwargs) -> pd.DataFrame
    """Carga datos de diferentes formatos."""
    
def clean_data(df) -> pd.DataFrame
    """Limpieza estÃ¡ndar de datos."""
    
def split_temporal(df, test_size=0.2) -> tuple
    """DivisiÃ³n respetando orden temporal."""
    
def create_sequences(series, lookback=10) -> tuple
    """Crea ventanas deslizantes para series temporales."""
```

### `visualization.py`
```python
def plot_confusion_matrix(y_true, y_pred, **kwargs)
    """Matriz de confusiÃ³n con Seaborn."""
    
def plot_roc_curve(y_true, y_proba, **kwargs)
    """Curva ROC con AUC."""
    
def plot_learning_curves(train_scores, test_scores, **kwargs)
    """Curvas de aprendizaje."""
    
def plot_feature_importance(model, feature_names, **kwargs)
    """Importancia de caracterÃ­sticas."""
```

### `model_evaluation.py`
```python
def evaluate_classification(y_true, y_pred, **kwargs) -> dict
    """MÃ©tricas completas de clasificaciÃ³n."""
    
def evaluate_regression(y_true, y_pred, **kwargs) -> dict
    """MÃ©tricas completas de regresiÃ³n."""
    
def cross_validate_model(model, X, y, **kwargs) -> dict
    """ValidaciÃ³n cruzada con mÃºltiples mÃ©tricas."""
    
def print_metrics(metrics, **kwargs)
    """Pretty print de mÃ©tricas."""
```

---

## ğŸ“š Contenido por Clase

### Resumen Ejecutivo

| Clase | Notebooks | Datasets | Scripts | Caso PrÃ¡ctico | Nivel |
|-------|-----------|----------|---------|---------------|-------|
| **01** | 3 | 5 | 2 | RetailBoost EDA | BÃ¡sico |
| **02** | 3 | 1 | 1 | RetailBoost RegresiÃ³n | BÃ¡sico |
| **03** | 2 | 1 | 0 | Churn Bancario | Intermedio |
| **04** | 1 | 1 | 0 | Leads Fintech | Intermedio |
| **05** | 1 | 0 | 0 | Ensambles | Intermedio |
| **06** | 3 | 0 | 0 | OptimizaciÃ³n | Avanzado |
| **07** | 2 | 3 | 0 | ShopSense Clustering | Intermedio |
| **08** | 2 | 4 | 0 | ShopSense Recomendaciones | Avanzado |
| **09** | 2 | 1 | 0 | CityScoot Forecasting | Avanzado |
| **10** | 4 | 2 | 0 | FinShield + EconoTrend | Avanzado |
| **11** | 0 | 0 | 0 | Consulta/Repaso | - |

---

## ğŸ¯ Casos PrÃ¡cticos por Dominio

### **Retail & E-commerce**
- **RetailBoost** (Clases 01-02): EDA y predicciÃ³n de valor de cliente
- **ShopSense** (Clases 07-08): SegmentaciÃ³n y recomendaciones

### **Finanzas & Fintech**
- **Churn Bancario** (Clase 03): PredicciÃ³n de abandono de clientes
- **MarTech** (Clase 04): ClasificaciÃ³n de leads de conversiÃ³n
- **EconoTrend** (Clase 10): PredicciÃ³n del Ã­ndice VIX (volatilidad)
- **FinShield** (Clase 10): DetecciÃ³n de fraude transaccional

### **Movilidad**
- **CityScoot** (Clase 09): Forecasting de demanda de scooters elÃ©ctricos

---

## ğŸ† Clase Destacada: Deep Learning (Clase 10)

### CaracterÃ­sticas especiales:

**DocumentaciÃ³n extensiva** (7 documentos en docs/):
1. `homework.md` - Consigna del trabajo
2. `resumen_contenidos.md` - TeorÃ­a de Deep Learning
3. `ANALISIS_COMPLETO_VIX_LSTM.md` - AnÃ¡lisis exhaustivo de resultados (447 lÃ­neas)
4. `LECTURAS_RECOMENDADAS_VIX_LSTM.md` - 30+ recursos organizados (382 lÃ­neas)
5. `VERIFICACION_AFIRMACIONES_DATOS.md` - 87 afirmaciones verificadas (257 lÃ­neas)
6. `INDICE_RAPIDO.md` - Referencia rÃ¡pida de valores
7. `README_ANALISIS_COMPLETO.md` - Ãndice maestro

**Material para instructores** (en notebooks/):
- `LECTURAS_COMPLETAS_POR_CELDA.md` - Script para comentarios en clase
- `CORRECCIONES.md` - Soluciones a problemas comunes

**Notebook principal**:
- `homework_vix_lstm_completo_didactico.ipynb`
- 3,066 lÃ­neas de cÃ³digo y documentaciÃ³n
- 1.6 MB de contenido didÃ¡ctico
- 100% ejecutable de principio a fin
- Incluye WIKIs, visualizaciones, lecturas recomendadas
- Basado en datos reales (outputs verificados)

---

## ğŸ”„ GestiÃ³n de Versiones

### Git Workflow

```bash
# Feature branch
git checkout -b feature/clase-12-nlp

# Commits descriptivos
git add .
git commit -m "Agrega notebooks de procesamiento de lenguaje natural"

# Push
git push origin feature/clase-12-nlp
```

### Semantic Versioning

- **Major (1.0.0)**: Cambios incompatibles (ej: nueva estructura de carpetas)
- **Minor (0.1.0)**: Nueva funcionalidad compatible (ej: nueva clase)
- **Patch (0.0.1)**: Bug fixes y mejoras menores

**VersiÃ³n actual**: 1.0.0

---

## ğŸ“ Mejores PrÃ¡cticas

### Notebooks

âœ… **SÃ hacer:**
- Estructura clara con secciones numeradas
- Tabla de contenidos con anclas (`<a id='seccion'></a>`)
- Comentarios explicativos en cÃ³digo
- Celdas cortas (<50 lÃ­neas)
- Seeds fijas (RANDOM_SEED = 42)
- Outputs relevantes (no todo el DataFrame)
- Visualizaciones con tÃ­tulos y labels
- Conclusiones al final

âŒ **NO hacer:**
- Celdas de 200+ lÃ­neas
- CÃ³digo sin comentarios
- Outputs de DataFrames completos (1000+ filas)
- Variables con nombres ambiguos (df1, df2, x, y)
- MÃºltiples versiones del mismo cÃ³digo
- Magic numbers (usar constantes)

### Scripts

âœ… **SÃ hacer:**
- Docstrings completos (Google/NumPy style)
- Type hints en firmas de funciones
- ValidaciÃ³n de inputs
- Manejo de errores con try/except
- Logging apropiado
- Tests unitarios

**Ejemplo:**

```python
def calculate_mae(y_true: np.ndarray, y_pred: np.ndarray) -> float:
    \"\"\"
    Calcula el Mean Absolute Error.
    
    Args:
        y_true: Valores reales. Shape: (N,)
        y_pred: Predicciones. Shape: (N,)
        
    Returns:
        MAE: Error absoluto medio
        
    Raises:
        ValueError: Si los arrays tienen shapes diferentes
        
    Example:
        >>> y_true = np.array([1, 2, 3])
        >>> y_pred = np.array([1.1, 2.2, 2.9])
        >>> calculate_mae(y_true, y_pred)
        0.13333...
    \"\"\"
    if y_true.shape != y_pred.shape:
        raise ValueError(f"Shapes no coinciden: {y_true.shape} vs {y_pred.shape}")
    
    return np.mean(np.abs(y_true - y_pred))
```

### DocumentaciÃ³n

**Cada clase debe tener:**

1. **README.md** con:
   - Objetivos de aprendizaje
   - Temas cubiertos
   - Archivos principales
   - Orden de estudio sugerido

2. **docs/resumen_contenidos.md** con:
   - TeorÃ­a de los temas
   - FÃ³rmulas y conceptos clave
   - Referencias y lecturas

3. **docs/homework.md** (si aplica) con:
   - Consigna clara
   - Datasets a usar
   - Criterios de evaluaciÃ³n
   - Entregables esperados

---

## ğŸ” GestiÃ³n de Secretos

### Variables de Entorno

**Archivo `.env.example`** (template):
```bash
# General
RANDOM_STATE=42
N_JOBS=-1
LOG_LEVEL=INFO

# Paths
DATA_DIR=./data
MODELS_DIR=./models

# API Keys (si se usan)
# KAGGLE_USERNAME=your_username
# KAGGLE_KEY=your_api_key
```

**âš ï¸ NUNCA commitear `.env` real** (incluido en `.gitignore`)

### Datos Sensibles

- Datasets pÃºblicos â†’ commit OK
- Datasets privados â†’ .gitignore + README con instrucciones de descarga
- API Keys â†’ variables de entorno
- ContraseÃ±as â†’ NUNCA en cÃ³digo

---

## ğŸš€ Escalabilidad

### Agregar Nueva Clase

```bash
# 1. Crear estructura
mkdir clase_XX_nombre_tema
cd clase_XX_nombre_tema
mkdir notebooks docs data

# 2. Crear README
touch README.md

# 3. Agregar notebooks
# ... crear notebooks en notebooks/

# 4. Actualizar README.md principal
# ... agregar la nueva clase a la tabla

# 5. Commit
git add .
git commit -m "Agrega clase XX: Nombre del Tema"
```

### Extender Utilidades (utils/)

1. Agregar funciÃ³n en mÃ³dulo apropiado
2. Actualizar `__init__.py` con export
3. Agregar tests en tests/
4. Documentar con docstring completo
5. Actualizar README si es pÃºblico

---

## ğŸ“š Dependencias Principales

### Core (Production)

```toml
python = "^3.9"
numpy = "^1.26.4"
pandas = "^2.3.3"
matplotlib = "^3.10.8"
seaborn = "^0.13.2"
scikit-learn = "^1.5.2"
torch = "^2.2.2"
xgboost = "^2.1.3"
lightgbm = "^4.5.0"
catboost = "^1.2.7"
statsmodels = "^0.14.4"
optuna = "^4.1.0"
jupyter = "^1.1.1"
jupyterlab = "^4.3.4"
```

### Development

```toml
pytest = "^8.3.4"
pytest-cov = "^6.0.0"
black = "^24.10.0"
flake8 = "^7.1.1"
mypy = "^1.13.0"
ipykernel = "^6.29.5"
```

**Total de dependencias**: ~50 paquetes (con subdependencias: ~200)

---

## ğŸ“Š Casos de Uso de Notebooks

### Por PropÃ³sito

| PropÃ³sito | Ejemplo | UbicaciÃ³n |
|-----------|---------|-----------|
| **IntroducciÃ³n teÃ³rica** | resumen_actividad_clase_01 | clase_01/notebooks |
| **Actividad en clase** | actividad_clase_02_regresion | clase_02/notebooks |
| **Homework** | homework_vix_lstm_completo | clase_10/notebooks |
| **Referencia rÃ¡pida** | econotrend_lstm_forecast | clase_10/notebooks |
| **ComparaciÃ³n de modelos** | 2_GradientBoosting_Optimizacion | clase_06/notebooks |

### Por Complejidad

| Nivel | Notebooks | Ejemplos |
|-------|-----------|----------|
| **Principiante** | 5 | EDA, RegresiÃ³n simple |
| **Intermedio** | 12 | ClasificaciÃ³n, Clustering |
| **Avanzado** | 6 | Series temporales, Deep Learning |

---

## ğŸŒ Recursos Externos

### DocumentaciÃ³n Oficial
- [Scikit-learn User Guide](https://scikit-learn.org/stable/user_guide.html)
- [PyTorch Tutorials](https://pytorch.org/tutorials/)
- [Pandas Documentation](https://pandas.pydata.org/docs/)
- [Statsmodels Documentation](https://www.statsmodels.org/)

### Papers Fundamentales
- Hochreiter & Schmidhuber (1997): "Long Short-Term Memory"
- Breiman (2001): "Random Forests"
- Chen & Guestrin (2016): "XGBoost: A Scalable Tree Boosting System"

### Cursos Complementarios
- [Fast.ai Practical Deep Learning](https://www.fast.ai/)
- [Andrew Ng - Machine Learning Specialization](https://www.coursera.org/specializations/machine-learning-introduction)
- [PyTorch Official Course](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html)

---

## ğŸ“ Habilidades Adquiridas

Al completar este curso, dominarÃ¡s:

âœ… **Fundamentos de ML**: Supervisado, no supervisado, validaciÃ³n  
âœ… **RegresiÃ³n y ClasificaciÃ³n**: Modelos lineales y no lineales  
âœ… **Ensambles**: Bagging, Boosting, Stacking  
âœ… **OptimizaciÃ³n**: Grid Search, Random Search, Optuna  
âœ… **Clustering**: K-Means, DBSCAN, Hierarchical  
âœ… **Recomendaciones**: Filtrado colaborativo y basado en contenido  
âœ… **Series Temporales**: ARIMA, Prophet, ML para forecasting  
âœ… **Deep Learning**: Redes densas, LSTM en PyTorch  
âœ… **Interpretabilidad**: SHAP, LIME, feature importance  
âœ… **Mejores prÃ¡cticas**: Reproducibilidad, documentaciÃ³n, testing

---

## ğŸ¤ ContribuciÃ³n

### CÃ³mo Contribuir

1. Fork el repositorio
2. Crea una rama para tu feature (`git checkout -b feature/nueva-clase`)
3. Commit tus cambios (`git commit -m 'Agrega clase XX'`)
4. Push a la rama (`git push origin feature/nueva-clase`)
5. Abre un Pull Request

Ver `CONTRIBUTING.md` para guÃ­a completa.

### QuÃ© Contribuir

- âœ… Nuevos notebooks de ejemplos
- âœ… Datasets adicionales
- âœ… Mejoras en documentaciÃ³n
- âœ… Correcciones de errores
- âœ… Casos de uso adicionales
- âœ… Scripts de utilidades

---

## ğŸ“ Soporte y Contacto

**Instructor**: Mariano Gobea  
**Email**: mariano.gobea@mercadolibre.com  
**Issues**: [GitHub Issues](https://github.com/tu-repo/data_science_henry/issues)

**Clase de consulta**: Lunes prÃ³ximo (Clase 11)

---

## ğŸ“œ Licencia

Este proyecto educativo estÃ¡ bajo la **Licencia MIT**.

```
Copyright (c) 2026 Mariano Gobea

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction...
```

Ver archivo `LICENSE` para el texto completo.

---

## ğŸ‰ Â¡Comienza Ya!

```bash
# 1. Clona o navega al proyecto
cd data_science_henry

# 2. Instala dependencias
poetry install

# 3. Activa entorno
poetry shell

# 4. Abre tu primer notebook
jupyter lab clase_01_introduccion_ml/notebooks/resumen_actividad_clase_01.ipynb
```

---

**Ãšltima actualizaciÃ³n**: Febrero 16, 2026  
**Mantenedor**: Mariano Gobea  
**VersiÃ³n**: 1.0.0

ğŸš€ **Â¡Ã‰xito en tu aprendizaje!**
