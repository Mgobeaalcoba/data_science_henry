## 2掳 avance --> Detalle

Gradient Boosting y Stacking

1
Random Forest y Gradient Boosting:

Random Forest y XGBoost:

Par谩metros clave: learning_rate, max_depth, n_estimators

Early stopping y otros par谩metros para evitar overfitting

Feature importance y gain

Regularizaci贸n alpha y lambda

LightGBM:

Optimizaci贸n para velocidad

Par谩metros espec铆ficos: num_leaves, min_data_in_leaf

Categorical feature handling

CatBoost:

Manejo autom谩tico de categ贸ricas

2
Validaci贸n cruzada y m茅tricas especializadas:

Estrategias de CV:

StratifiedKFold para datos desbalanceados

GroupKFold para datos agrupados

StratifiedGroupKFold para datos desbalanceados y agrupados

TimeSeriesSplit para datos temporales

M茅tricas de evaluaci贸n:

Accuracy, Recall, y Precision

PR-AUC para datos desbalanceados

ROC-AUC para datos desbalanceados

Business metrics personalizadas

3
Stacking y Blending:

Stacking:

Nivel 1: XGBoost, LightGBM, CatBoost

Meta-learner: Regresi贸n Log铆stica regularizada

Cross-validation para evitar overfitting

Blending:

Holdout set para meta-learner

Ponderaci贸n 贸ptima de modelos

4
Optimizaci贸n de hiperpar谩metros avanzada:

Bayesian Optimization con Optuna:

Objective function personalizada

Visualizaci贸n de importancia de hiperpar谩metros

Grid Search y Random Search:

Comparaci贸n de eficiencia

Nested cross-validation

## Consigna

Deber谩s entregar el notebook 2_GradientBoosting_Optimizacion.ipynb donde compares los resultados de la ejecuci贸n de los algoritmos de Random Forest, Gradient Boosting (xGBoost, LightGBM, y CatBoost), y un ensamble de modelos (solo Stacking).
Es clave que apliques optimizaci贸n de hiperpar谩metros solamente al modelo XGBoost,  utilizando Grid Search.

La optimizaci贸n utilizando Optuna es opcional, siendo bueno mencionar que hoy en d铆a es ampliamente utilizada.  Es caso de decidir hacerla utilizar 50 trials.

 Conocimientos necesarios
Algoritmos de Gradient Boosting

T茅cnicas de ensemble (Stacking, Blending)

Optimizaci贸n bayesiana

Validaci贸n cruzada

M茅tricas de evaluaci贸n para modelos de clasificaci贸n

 Tech Stack necesario
XGBoost, LightGBM, CatBoost

Optuna, Random/Grid Search

Scikit-learn (ensemble methods)