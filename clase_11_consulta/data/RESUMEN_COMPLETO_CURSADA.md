# üìö RESUMEN COMPLETO DE LA CURSADA
## Data Science y Machine Learning - Henry

**Fecha**: Febrero 2026  
**Prop√≥sito**: Repaso pre-proyecto final  
**Clase de Consulta**: Lunes pr√≥ximo

---

## üéØ √çNDICE R√ÅPIDO

1. [Estad√≠sticas de la Cursada](#estadisticas)
2. [M√≥dulo 1: Fundamentos de ML](#modulo1)
3. [M√≥dulo 2: Modelos Avanzados](#modulo2)
4. [M√≥dulo 3: No Supervisado](#modulo3)
5. [M√≥dulo 4: Series Temporales y Deep Learning](#modulo4)
6. [Resumen de Datasets](#datasets)
7. [Resumen de Algoritmos](#algoritmos)
8. [M√©tricas por Tipo de Problema](#metricas)
9. [Checklist de Habilidades](#checklist)
10. [Recursos para Proyecto Final](#proyecto)

---

<a id='estadisticas'></a>
## üìä ESTAD√çSTICAS DE LA CURSADA

### Contenido Total

| M√©trica | Cantidad | Detalles |
|---------|----------|----------|
| **Clases te√≥rico-pr√°cticas** | 10 | + 1 clase de consulta |
| **Notebooks ejecutados** | 23 | Jupyter notebooks interactivos |
| **Datasets analizados** | 20 | Casos reales de diferentes dominios |
| **Algoritmos cubiertos** | 25+ | De regresi√≥n lineal a LSTM |
| **L√≠neas de c√≥digo** | ~15,000 | Entre todos los notebooks |
| **Horas de contenido** | ~32h | Teor√≠a + pr√°ctica |
| **Scripts Python** | 3 | En clase_01 y clase_02 |
| **Documentos de referencia** | 31 | Teor√≠a, homeworks, gu√≠as |

### Tecnolog√≠as Dominadas

| Categor√≠a | Herramientas |
|-----------|-------------|
| **Data Science** | NumPy, Pandas, Matplotlib, Seaborn |
| **ML Cl√°sico** | Scikit-learn |
| **Gradient Boosting** | XGBoost, LightGBM, CatBoost |
| **Deep Learning** | PyTorch |
| **Series Temporales** | Statsmodels, Prophet |
| **Optimizaci√≥n** | Optuna |
| **Interpretabilidad** | SHAP, LIME |

---

<a id='modulo1'></a>
## üìñ M√ìDULO 1: FUNDAMENTOS DE MACHINE LEARNING

### **Clase 01: Introducci√≥n al ML**

**Conceptos clave:**
- IA vs ML vs DL vs GenAI (jerarqu√≠a de t√©rminos)
- Tipos de aprendizaje: supervisado, no supervisado, por refuerzo
- Elementos de un modelo: features, target, par√°metros, hiperpar√°metros
- Funci√≥n de costo y proceso de optimizaci√≥n
- Underfitting (alto sesgo) vs Overfitting (alta varianza)
- Pipeline de ML: problema ‚Üí datos ‚Üí modelo ‚Üí evaluaci√≥n ‚Üí deployment

**Caso pr√°ctico**: RetailBoost - EDA de clientes  
**Dataset**: `retailboost_customers.csv` (5 versiones)  
**T√©cnicas**: An√°lisis exploratorio, detecci√≥n de outliers, correlaciones

**Lo m√°s importante para recordar:**
- **Feature engineering** es el 70% del √©xito en ML
- **EDA** es obligatorio antes de modelar
- **Overfitting** es el enemigo #1 (m√°s datos, menos complejidad, regularizaci√≥n)

---

### **Clase 02: Regresi√≥n**

**Algoritmos:**
- Regresi√≥n Lineal Simple
- Regresi√≥n Lineal M√∫ltiple
- Regresi√≥n Polin√≥mica
- Ridge Regression (L2)
- Lasso Regression (L1)
- ElasticNet (L1 + L2)

**M√©tricas:**
```
MAE  = (1/n) Œ£|y_true - y_pred|
MSE  = (1/n) Œ£(y_true - y_pred)¬≤
RMSE = ‚àöMSE
R¬≤   = 1 - (SS_res / SS_tot)
MAPE = (100/n) Œ£|(y_true - y_pred) / y_true|
```

**Caso pr√°ctico**: RetailBoost - Predicci√≥n de valor de cliente  
**Dataset**: `retailboost_customers_regression.csv`

**Lo m√°s importante:**
- **R¬≤ = 0.70** es bueno, **0.85** es muy bueno, **0.95** es sospechoso (posible overfitting)
- **Regularizaci√≥n** (Ridge/Lasso) previene overfitting
- **Validaci√≥n cruzada** es esencial (K-Fold, t√≠picamente k=5 o 10)
- **Multicolinealidad** afecta interpretabilidad pero no predicci√≥n

---

### **Clase 03: Regresi√≥n Log√≠stica**

**Conceptos:**
- Funci√≥n sigmoide: œÉ(z) = 1 / (1 + e^(-z))
- Log-loss (Binary Cross-Entropy)
- Odds ratio e interpretaci√≥n de coeficientes
- Clasificaci√≥n multiclase: One-vs-Rest (OvR), One-vs-One (OvO), Softmax

**M√©tricas de clasificaci√≥n:**
```
Accuracy  = (TP + TN) / (TP + TN + FP + FN)
Precision = TP / (TP + FP)       # "De lo que predije positivo, cu√°nto acert√©"
Recall    = TP / (TP + FN)       # "De lo realmente positivo, cu√°nto detect√©"
F1-Score  = 2 √ó (Precision √ó Recall) / (Precision + Recall)
ROC-AUC   = √Årea bajo la curva ROC
```

**Caso pr√°ctico**: Churn bancario  
**Dataset**: `Churn_Modelling.csv`

**Lo m√°s importante:**
- **Regresi√≥n log√≠stica** es clasificaci√≥n (nombre confuso pero est√°ndar)
- **ROC-AUC = 0.50** es random, **0.70** es aceptable, **0.85+** es excelente
- **Precision vs Recall**: Trade-off seg√∫n costos de FP vs FN
- **Umbral = 0.5** es default pero debe ajustarse seg√∫n el negocio

---

### **Clase 04: Clasificaci√≥n y M√©tricas**

**Algoritmos:**
- K-Nearest Neighbors (KNN)
- Decision Trees (CART)
- Random Forest (Bagging de √°rboles)
- Support Vector Machines (SVM) con kernels (linear, RBF, poly)

**Caso pr√°ctico**: Clasificaci√≥n de leads fintech  
**Dataset**: `martech_homework_dataset_fixed.csv`

**Lo m√°s importante:**
- **KNN**: Simple pero lento (c√°lculo de distancias), sensible a escala
- **Decision Trees**: Interpretables pero propensos a overfitting
- **Random Forest**: Robusto, menos overfitting, m√°s lento
- **SVM con kernel RBF**: Poderoso pero requiere tuning (C, gamma)
- **Clases desbalanceadas**: Usar F1-Score, ROC-AUC, o balancear datos

---

<a id='modulo2'></a>
## üîß M√ìDULO 2: MODELOS AVANZADOS Y OPTIMIZACI√ìN

### **Clase 05: Modelos de Ensamble**

**Conceptos:**
- **Trade-off sesgo-varianza**: Sesgo = error sistem√°tico, Varianza = sensibilidad a datos
- **Bagging**: Reduce varianza (ej: Random Forest)
- **Boosting**: Reduce sesgo (ej: XGBoost)
- **Stacking**: Combina modelos heterog√©neos
- **Voting**: Promedio de predicciones

**Algoritmos de Boosting:**
1. **XGBoost**: El m√°s popular, muy r√°pido
2. **LightGBM**: M√°s r√°pido a√∫n, para datasets grandes
3. **CatBoost**: Maneja categ√≥ricas autom√°ticamente

**Lo m√°s importante:**
- **Boosting** suele ganar en Kaggle (XGBoost, LightGBM)
- **Random Forest** es m√°s robusto (menos overfitting)
- **Hiperpar√°metros clave**: n_estimators, max_depth, learning_rate
- **Riesgo**: Boosting puede hacer overfitting si no se regula

---

### **Clase 06: Optimizaci√≥n de Modelos**

**T√©cnicas:**
1. **Grid Search**: Busca exhaustivamente (lento pero seguro)
2. **Random Search**: Busca aleatoriamente (m√°s r√°pido)
3. **B√∫squeda Bayesiana** (Optuna): Inteligente, aprende de intentos previos

**Validaci√≥n:**
- K-Fold Cross-Validation (t√≠picamente k=5 o 10)
- Stratified K-Fold (para clasificaci√≥n desbalanceada)
- Time Series Split (para series temporales)

**Regularizaci√≥n:**
- L1 (Lasso): Fuerza coeficientes a cero (feature selection)
- L2 (Ridge): Reduce magnitud de coeficientes
- Dropout: Apaga neuronas aleatoriamente (DL)
- Early Stopping: Detiene entrenamiento antes de overfitting

**Lo m√°s importante:**
- **Optuna** es superior a Grid Search (m√°s eficiente)
- **Validaci√≥n cruzada** es obligatoria (no confiar en un solo split)
- **Feature selection** mejora generalizaci√≥n y interpretabilidad
- **Regularizaci√≥n** siempre debe considerarse

---

<a id='modulo3'></a>
## üîç M√ìDULO 3: APRENDIZAJE NO SUPERVISADO

### **Clase 07: Clustering y Segmentaci√≥n**

**Algoritmos:**
1. **K-Means**: Simple, r√°pido, asume clusters esf√©ricos
2. **DBSCAN**: Detecta formas arbitrarias, identifica outliers
3. **Hierarchical**: Dendrogram, decide k despu√©s

**M√©tricas:**
- **Elbow method**: Encuentra k √≥ptimo (punto de inflexi√≥n)
- **Silhouette Score**: [-1, 1], >0.5 es bueno
- **Davies-Bouldin Index**: Menor es mejor
- **Calinski-Harabasz**: Mayor es mejor

**T√©cnicas complementarias:**
- **PCA**: Reducci√≥n de dimensionalidad lineal
- **t-SNE**: Visualizaci√≥n en 2D/3D (no lineal)
- **An√°lisis RFM**: Recency, Frequency, Monetary (retail)

**Caso pr√°ctico**: ShopSense - Segmentaci√≥n de clientes  
**Datasets**: `Mall_Customers.csv`, `shopsense_customers_clean.csv`

**Lo m√°s importante:**
- **K-Means** requiere normalizaci√≥n (sensible a escala)
- **No hay "verdad" en clustering** (no hay y_true)
- **PCA** para reducir dimensiones antes de clustering
- **Interpretar clusters** es tan importante como crearlos

---

### **Clase 08: Sistemas de Recomendaci√≥n**

**Enfoques:**
1. **Filtrado Colaborativo**:
   - User-Based: "Usuarios similares a ti compraron..."
   - Item-Based: "√çtems similares a los que te gustan..."
   
2. **Filtrado Basado en Contenido**:
   - Usa features de √≠tems (g√©nero, categor√≠a, etc.)
   
3. **H√≠bridos**:
   - Combina colaborativo + contenido

**M√©tricas:**
```
Precision@K = (# relevant items in top-K) / K
Recall@K    = (# relevant items in top-K) / (total relevant)
NDCG@K      = Normalized Discounted Cumulative Gain (considera orden)
```

**Librer√≠a**: Surprise (para collaborative filtering)

**Caso pr√°ctico**: ShopSense - Recomendaci√≥n de productos  
**Datasets**: `users_clean.csv`, `items.csv`, `interactions.csv`

**Lo m√°s importante:**
- **Cold start problem**: Nuevos usuarios/√≠tems sin historial
- **Precision@K** m√°s importante que Recall@K en producci√≥n
- **Diversidad** y **novedad** tambi√©n importan (no solo accuracy)
- **Escalabilidad** es cr√≠tica (millones de usuarios √ó productos)

---

<a id='modulo4'></a>
## üìà M√ìDULO 4: SERIES TEMPORALES Y DEEP LEARNING

### **Clase 09: An√°lisis de Series Temporales**

**Componentes:**
- **Tendencia**: Movimiento a largo plazo (‚ÜóÔ∏è ‚ÜòÔ∏è ‚Üí)
- **Estacionalidad**: Patrones repetitivos (diario, semanal, anual)
- **Ciclo**: Fluctuaciones no peri√≥dicas
- **Ruido**: Variabilidad aleatoria

**Test de Estacionariedad:**
- **ADF (Augmented Dickey-Fuller)**:
  - H0: Serie tiene ra√≠z unitaria (NO estacionaria)
  - Si p < 0.05 ‚Üí Serie es estacionaria
  
**Autocorrelaci√≥n:**
- **ACF**: Correlaci√≥n con lags pasados
- **PACF**: Correlaci√≥n directa (sin intermediarios)

**Modelos:**
1. **ARIMA(p,d,q)**: Cl√°sico, requiere estacionariedad
   - p = orden AR (autoregressive)
   - d = orden de diferenciaci√≥n
   - q = orden MA (moving average)
   
2. **SARIMA**: ARIMA + componente estacional

3. **Prophet** (Facebook): Autom√°tico, maneja holidays y outliers

4. **ML para forecasting**: Random Forest, XGBoost con lags como features

**Caso pr√°ctico**: CityScoot - Predicci√≥n de demanda diaria  
**Dataset**: `cityscoot_daily_rides.csv`

**Lo m√°s importante:**
- **Validaci√≥n temporal**: NUNCA shuffle, respetar orden cronol√≥gico
- **Data leakage**: No usar informaci√≥n del futuro
- **Baseline**: Modelo de persistencia (≈∑_t = y_{t-1})
- **Walk-forward validation**: Reentrenar con ventana deslizante

---

### **Clase 10: Introducci√≥n al Deep Learning** ‚≠ê

**Fundamentos:**
- **Perceptr√≥n**: Neurona artificial b√°sica
- **Activaciones**: ReLU, Sigmoid, Tanh, Softmax
- **Forward pass**: Datos ‚Üí Predicciones
- **Backward pass**: Gradientes ‚Üí Actualizaci√≥n de pesos
- **Funci√≥n de p√©rdida**: MSE (regresi√≥n), Cross-Entropy (clasificaci√≥n)
- **Optimizadores**: SGD, Adam, RMSprop

**Arquitecturas:**
1. **Redes Densas (Feedforward)**:
   - Para datos tabulares
   - Capas fully connected
   - Activaci√≥n ReLU en ocultas
   
2. **LSTM (Long Short-Term Memory)**:
   - Para series temporales
   - Memoria a largo plazo
   - Gates: forget, input, output, cell state

**PyTorch - Componentes:**
- **Tensors**: Arrays multidimensionales (como NumPy + GPU)
- **Autograd**: Diferenciaci√≥n autom√°tica
- **nn.Module**: Clase base para modelos
- **Dataset/DataLoader**: Carga eficiente de datos
- **Loss functions**: nn.MSELoss(), nn.CrossEntropyLoss()
- **Optimizers**: torch.optim.Adam(), torch.optim.SGD()

**Casos pr√°cticos:**

#### 1. **FinShield: Detecci√≥n de Fraude**
- **Dataset**: `finshield_transactions_clean.csv` (10k transacciones)
- **Modelo**: Red densa (3 capas)
- **T√©cnica**: Clasificaci√≥n binaria
- **M√©tricas**: ROC-AUC, Precision, Recall

#### 2. **EconoTrend: Predicci√≥n del VIX**
- **Dataset**: `econotrend_vix_sim.csv` (1,305 observaciones, 5 a√±os)
- **Modelo**: LSTM (2 capas √ó 64 unidades = 50K par√°metros)
- **T√©cnica**: Predicci√≥n de series temporales
- **Resultados reales**:
  - MAE = 0.946 puntos VIX
  - R¬≤ = 0.666 (66.6% varianza explicada)
  - Mejora vs baseline = 1.88%
  - Tiempo entrenamiento = 5.47s (50 √©pocas)

**Lo m√°s importante:**
- **Normalizaci√≥n** es cr√≠tica (MinMaxScaler o StandardScaler)
- **Batch size**: T√≠picamente 32, 64, 128 (potencias de 2)
- **Learning rate**: 0.001 es un buen default para Adam
- **Dropout** (0.2-0.5) previene overfitting
- **Early stopping**: Monitorear validation loss
- **GPU** acelera 5-10x vs CPU (pero no esencial para datasets peque√±os)

**Ventanas deslizantes (LSTM)**:
```
Serie: [v1, v2, v3, v4, v5, v6, ...]

Con LOOKBACK=3:
X               y
[v1, v2, v3] ‚Üí v4
[v2, v3, v4] ‚Üí v5
[v3, v4, v5] ‚Üí v6
...
```

---

<a id='datasets'></a>
## üìä RESUMEN DE DATASETS

### Por Dominio

**Retail & E-commerce:**
1. `retailboost_customers.csv` - Clientes retail (EDA + Regresi√≥n)
2. `Mall_Customers.csv` - Segmentaci√≥n de clientes mall
3. `shopsense_customers_clean.csv` - Clientes e-commerce
4. `items.csv` - Cat√°logo de productos
5. `interactions.csv` - Interacciones user-item

**Finanzas & Fintech:**
6. `Churn_Modelling.csv` - Churn bancario
7. `martech_homework_dataset_fixed.csv` - Leads fintech
8. `econotrend_vix_sim.csv` - √çndice VIX (volatilidad mercado)
9. `finshield_transactions_clean.csv` - Transacciones (fraude)

**Movilidad:**
10. `cityscoot_daily_rides.csv` - Demanda diaria scooters

### Caracter√≠sticas de los Datasets

| Dataset | Filas | Columnas | Tipo | Desbalance |
|---------|-------|----------|------|------------|
| retailboost | ~1,000 | 10-15 | Tabular | Balanceado |
| Churn_Modelling | ~10,000 | 14 | Tabular | Desbalanceado (20% churn) |
| martech | ~5,000 | 8 | Tabular | Desbalanceado |
| shopsense | ~2,000 | 8 | Tabular | Balanceado |
| cityscoot | 365 | 6 | Series temporal | N/A |
| econotrend_vix | 1,305 | 2 | Series temporal | N/A |
| finshield | 10,000 | 10 | Tabular | Muy desbalanceado (<1% fraude) |

---

<a id='algoritmos'></a>
## ü§ñ RESUMEN DE ALGORITMOS

### Clasificaci√≥n (Completa)

| Algoritmo | Ventajas | Desventajas | Cu√°ndo usar |
|-----------|----------|-------------|-------------|
| **Regresi√≥n Log√≠stica** | Simple, interpretable, r√°pido | Solo fronteras lineales | Baseline, interpretabilidad |
| **KNN** | No param√©trico, simple | Lento, sensible a escala | Pocos datos, fronteras complejas |
| **Decision Tree** | Interpretable, no requiere normalizaci√≥n | Overfitting f√°cil | Interpretabilidad |
| **Random Forest** | Robusto, feature importance | Menos interpretable, lento | Buena relaci√≥n performance/effort |
| **XGBoost** | Muy preciso, r√°pido | Requiere tuning | Competencias, producci√≥n |
| **SVM (RBF)** | Fronteras complejas | Lento, tuning dif√≠cil | Pocos datos, alta dimensionalidad |
| **Red Densa (DL)** | Aprende features, no lineal | Caja negra, requiere m√°s datos | Datos tabulares complejos |

### Regresi√≥n

| Algoritmo | Regularizaci√≥n | Complejidad | Cu√°ndo usar |
|-----------|----------------|-------------|-------------|
| **Regresi√≥n Lineal** | No | Baja | Baseline, relaciones lineales |
| **Ridge** | L2 | Baja | Multicolinealidad |
| **Lasso** | L1 | Baja | Feature selection autom√°tico |
| **ElasticNet** | L1 + L2 | Baja | Muchas features correlacionadas |
| **Polynomial Reg** | - | Media | Relaciones no lineales |
| **Random Forest** | - | Alta | No linealidad, robustez |
| **XGBoost** | L1/L2 | Alta | M√°xima precisi√≥n |
| **LSTM** | Dropout | Muy Alta | Series temporales |

### Clustering

| Algoritmo | Ventajas | Desventajas | Cu√°ndo usar |
|-----------|----------|-------------|-------------|
| **K-Means** | R√°pido, simple | Asume esferas, requiere k | Clusters esf√©ricos |
| **DBSCAN** | Formas arbitrarias, detecta outliers | Sensible a Œµ y min_samples | Densidad variable |
| **Hierarchical** | No requiere k, dendrogram | Lento (O(n¬≥)) | Visualizaci√≥n jer√°rquica |

---

<a id='metricas'></a>
## üìè M√âTRICAS POR TIPO DE PROBLEMA

### Regresi√≥n

```python
from sklearn.metrics import (
    mean_absolute_error,         # MAE
    mean_squared_error,          # MSE, RMSE
    r2_score,                    # R¬≤
    mean_absolute_percentage_error  # MAPE
)

mae = mean_absolute_error(y_true, y_pred)
rmse = mean_squared_error(y_true, y_pred, squared=False)
r2 = r2_score(y_true, y_pred)
```

**Interpretaci√≥n:**
- **MAE**: Error promedio en unidades de y
- **RMSE**: Penaliza errores grandes m√°s que MAE
- **R¬≤**: [0, 1], fracci√≥n de varianza explicada
- **MAPE**: Error porcentual (cuidado con y=0)

---

### Clasificaci√≥n

```python
from sklearn.metrics import (
    accuracy_score,
    precision_score,
    recall_score,
    f1_score,
    roc_auc_score,
    confusion_matrix,
    classification_report
)

accuracy = accuracy_score(y_true, y_pred)
precision = precision_score(y_true, y_pred)
recall = recall_score(y_true, y_pred)
f1 = f1_score(y_true, y_pred)
auc = roc_auc_score(y_true, y_proba)
```

**Cu√°ndo usar cada m√©trica:**
- **Accuracy**: Solo si clases est√°n balanceadas
- **Precision**: Minimizar falsos positivos (ej: spam detection)
- **Recall**: Minimizar falsos negativos (ej: detecci√≥n de fraude)
- **F1-Score**: Balance entre Precision y Recall
- **ROC-AUC**: Rendimiento global, robusto a desbalance

---

### Clustering

```python
from sklearn.metrics import (
    silhouette_score,
    davies_bouldin_score,
    calinski_harabasz_score
)

silhouette = silhouette_score(X, labels)  # [-1, 1], mayor mejor
davies_bouldin = davies_bouldin_score(X, labels)  # [0, ‚àû), menor mejor
calinski = calinski_harabasz_score(X, labels)  # [0, ‚àû), mayor mejor
```

---

### Series Temporales

```python
# Mismas que regresi√≥n + espec√≠ficas:
from sklearn.metrics import mean_absolute_percentage_error

mape = mean_absolute_percentage_error(y_true, y_pred)

# Baseline: Modelo de persistencia
baseline_pred = y_test[:-1]  # ≈∑_t = y_{t-1}
baseline_mae = mean_absolute_error(y_test[1:], baseline_pred)

# Tu modelo debe superar el baseline
if model_mae < baseline_mae:
    print("‚úÖ Modelo funciona")
else:
    print("‚ùå Modelo no supera baseline (random walk)")
```

---

<a id='checklist'></a>
## ‚úÖ CHECKLIST DE HABILIDADES ADQUIRIDAS

### Data Science

- [ ] Cargar y explorar datos con Pandas
- [ ] Visualizar distribuciones (histogramas, boxplots, scatter)
- [ ] Detectar y manejar valores faltantes
- [ ] Identificar y tratar outliers
- [ ] Analizar correlaciones
- [ ] Feature engineering (crear nuevas variables)
- [ ] Normalizaci√≥n y estandarizaci√≥n
- [ ] Encoding de variables categ√≥ricas (One-Hot, Label Encoding)

### Machine Learning

#### Supervisado
- [ ] Regresi√≥n lineal simple y m√∫ltiple
- [ ] Regularizaci√≥n (Ridge, Lasso, ElasticNet)
- [ ] Regresi√≥n log√≠stica para clasificaci√≥n
- [ ] Interpretar odds ratios
- [ ] K-Nearest Neighbors
- [ ] Decision Trees
- [ ] Random Forest
- [ ] Gradient Boosting (XGBoost, LightGBM, CatBoost)
- [ ] Support Vector Machines
- [ ] Ensambles (Voting, Stacking, Blending)

#### No Supervisado
- [ ] K-Means clustering
- [ ] DBSCAN
- [ ] Hierarchical clustering
- [ ] PCA para reducci√≥n de dimensionalidad
- [ ] t-SNE para visualizaci√≥n
- [ ] Sistemas de recomendaci√≥n (collaborative filtering)

#### Series Temporales
- [ ] Descomposici√≥n (tendencia, estacionalidad, residuos)
- [ ] Test de estacionariedad (ADF)
- [ ] ACF y PACF
- [ ] ARIMA y SARIMA
- [ ] Prophet
- [ ] Forecasting con ML (lags como features)
- [ ] Validaci√≥n temporal

#### Deep Learning
- [ ] Redes neuronales densas
- [ ] Funci√≥n de activaci√≥n (ReLU, Sigmoid, Softmax)
- [ ] Forward y backward propagation
- [ ] Funciones de p√©rdida (MSE, Cross-Entropy)
- [ ] Optimizadores (Adam, SGD)
- [ ] Regularizaci√≥n (Dropout, Early Stopping)
- [ ] LSTM para series temporales
- [ ] PyTorch: Tensors, nn.Module, DataLoader

### Evaluaci√≥n y Optimizaci√≥n

- [ ] Train/test split (y validaci√≥n)
- [ ] K-Fold cross-validation
- [ ] Grid Search
- [ ] Random Search
- [ ] B√∫squeda bayesiana (Optuna)
- [ ] M√©tricas de regresi√≥n (MAE, RMSE, R¬≤)
- [ ] M√©tricas de clasificaci√≥n (Accuracy, Precision, Recall, F1, ROC-AUC)
- [ ] Matriz de confusi√≥n
- [ ] Curva ROC
- [ ] Feature importance
- [ ] SHAP values (interpretabilidad)

### Herramientas

- [ ] Jupyter/JupyterLab
- [ ] Git para control de versiones
- [ ] Poetry para gesti√≥n de dependencias
- [ ] Pandas para manipulaci√≥n de datos
- [ ] Scikit-learn para ML cl√°sico
- [ ] PyTorch para Deep Learning
- [ ] Matplotlib/Seaborn para visualizaci√≥n
- [ ] Optuna para optimizaci√≥n

---

<a id='proyecto'></a>
## üéØ RECURSOS PARA PROYECTO FINAL

### Estructura Sugerida del Proyecto

```
mi_proyecto_final/
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ 01_eda.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 02_preprocessing.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 03_baseline_models.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 04_advanced_models.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 05_optimization.ipynb
‚îÇ   ‚îî‚îÄ‚îÄ 06_final_model_evaluation.ipynb
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îî‚îÄ‚îÄ utils/
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/
‚îÇ   ‚îî‚îÄ‚îÄ processed/
‚îú‚îÄ‚îÄ models/                    # Modelos guardados
‚îú‚îÄ‚îÄ reports/                   # PDFs, presentaciones
‚îú‚îÄ‚îÄ README.md
‚îî‚îÄ‚îÄ requirements.txt
```

### Checklist del Proyecto

**1. Definici√≥n del Problema** (10%)
- [ ] Descripci√≥n clara del problema de negocio
- [ ] Objetivo cuantificable
- [ ] Justificaci√≥n de por qu√© ML es apropiado

**2. Datos** (15%)
- [ ] Descripci√≥n del dataset (origen, tama√±o, features)
- [ ] Justificaci√≥n de train/test split
- [ ] Manejo de datos faltantes documentado

**3. EDA** (20%)
- [ ] Estad√≠sticas descriptivas
- [ ] Visualizaciones de distribuciones
- [ ] An√°lisis de correlaciones
- [ ] Detecci√≥n de outliers
- [ ] Feature engineering justificado

**4. Preprocesamiento** (10%)
- [ ] Normalizaci√≥n/estandarizaci√≥n
- [ ] Encoding de categ√≥ricas
- [ ] Manejo de outliers
- [ ] Feature selection (si aplica)

**5. Modelado** (25%)
- [ ] Al menos 3 algoritmos diferentes
- [ ] Baseline simple (ej: persistencia, media, regresi√≥n lineal)
- [ ] Modelos avanzados (RF, XGBoost, DL, etc.)
- [ ] Validaci√≥n cruzada

**6. Optimizaci√≥n** (10%)
- [ ] Tuning de hiperpar√°metros (Grid Search, Optuna)
- [ ] Comparaci√≥n de modelos
- [ ] Selecci√≥n del mejor modelo justificada

**7. Evaluaci√≥n** (15%)
- [ ] M√©tricas apropiadas al problema
- [ ] Matriz de confusi√≥n (si clasificaci√≥n)
- [ ] An√°lisis de errores
- [ ] Comparaci√≥n con baseline

**8. Interpretabilidad** (5% bonus)
- [ ] Feature importance
- [ ] SHAP values
- [ ] Explicaci√≥n de predicciones espec√≠ficas

**9. Conclusiones** (5%)
- [ ] Resumen de resultados
- [ ] Recomendaciones de negocio
- [ ] Limitaciones y pr√≥ximos pasos

---

## üí° CONSEJOS PARA EL PROYECTO FINAL

### Errores Comunes a Evitar

‚ùå **NO hacer:**
1. Saltar el EDA (ir directo al modelo)
2. Usar Accuracy en datos desbalanceados
3. No comparar con un baseline
4. Overfitting ignorado (solo reportar train metrics)
5. No documentar decisiones
6. Modelos sin interpretabilidad
7. Conclusiones gen√©ricas (no espec√≠ficas al negocio)
8. Data leakage (usar informaci√≥n del futuro/test en train)

‚úÖ **S√ç hacer:**
1. EDA exhaustivo con visualizaciones
2. Baseline simple primero
3. Al menos 3 modelos diferentes
4. Validaci√≥n cruzada obligatoria
5. Documentar cada decisi√≥n importante
6. Feature importance o SHAP
7. Conclusiones de negocio (no solo t√©cnicas)
8. README profesional con instrucciones de reproducci√≥n

### Datasets Recomendados

**Opci√≥n 1: Usa los del curso**
- RetailBoost (regresi√≥n)
- Churn bancario (clasificaci√≥n)
- ShopSense (clustering + recomendaciones)
- CityScoot (series temporales)

**Opci√≥n 2: Kaggle**
- [House Prices](https://www.kaggle.com/c/house-prices-advanced-regression-techniques) - Regresi√≥n
- [Titanic](https://www.kaggle.com/c/titanic) - Clasificaci√≥n binaria
- [Credit Card Fraud](https://www.kaggle.com/mlg-ulb/creditcardfraud) - Clasificaci√≥n desbalanceada
- [Store Sales Forecasting](https://www.kaggle.com/c/store-sales-time-series-forecasting) - Series temporales

**Opci√≥n 3: UCI ML Repository**
- [Adult Income](https://archive.ics.uci.edu/ml/datasets/adult) - Clasificaci√≥n
- [Wine Quality](https://archive.ics.uci.edu/ml/datasets/wine+quality) - Regresi√≥n/Clasificaci√≥n
- [Bike Sharing](https://archive.ics.uci.edu/ml/datasets/bike+sharing+dataset) - Series temporales

### M√©tricas M√≠nimas Requeridas

**Regresi√≥n:**
- MAE
- RMSE
- R¬≤

**Clasificaci√≥n:**
- Matriz de confusi√≥n
- Precision, Recall, F1-Score
- ROC-AUC (si binaria)

**Series Temporales:**
- MAE
- RMSE
- Comparaci√≥n con baseline (persistencia)

**Clustering:**
- Silhouette Score
- Elbow plot
- Interpretaci√≥n de clusters

---

## üìÖ CRONOGRAMA SUGERIDO PARA PROYECTO

**2 semanas antes de entrega:**
- Selecci√≥n de dataset y definici√≥n de problema
- EDA completo
- Baseline implementado

**1 semana antes:**
- Modelos avanzados implementados
- Optimizaci√≥n de hiperpar√°metros
- Evaluaci√≥n comparativa

**3 d√≠as antes:**
- Interpretabilidad y visualizaciones finales
- Documentaci√≥n completa
- Revisi√≥n final

**1 d√≠a antes:**
- Presentaci√≥n preparada
- C√≥digo limpio y ejecutable
- README profesional

---

## üîó ENLACES R√ÅPIDOS

### Documentaci√≥n del Curso
- [README Principal](../README.md)
- [QUICKSTART](../QUICKSTART.md)
- [ARCHITECTURE](../ARCHITECTURE.md) (este archivo)
- [CONTRIBUTING](../CONTRIBUTING.md)

### Clase 10 (Deep Learning) - Material Extra
- [An√°lisis Completo VIX-LSTM](../clase_10_deep_learning/docs/ANALISIS_COMPLETO_VIX_LSTM.md)
- [Lecturas Recomendadas](../clase_10_deep_learning/docs/LECTURAS_RECOMENDADAS_VIX_LSTM.md)
- [Verificaci√≥n de Datos](../clase_10_deep_learning/docs/VERIFICACION_AFIRMACIONES_DATOS.md)
- [Gu√≠a para Instructores](../clase_10_deep_learning/notebooks/LECTURAS_COMPLETAS_POR_CELDA.md)

---

## üìß Contacto y Soporte

**Instructor**: Mariano Gobea  
**Email**: mariano.gobea@mercadolibre.com  
**Clase de Consulta**: Lunes pr√≥ximo

**Para dudas urgentes**: Usa el sistema de issues del repositorio

---

**√öltima actualizaci√≥n**: Febrero 16, 2026  
**Pr√≥xima revisi√≥n**: Post proyecto final

üéì **¬°√âxito en tu proyecto!**
