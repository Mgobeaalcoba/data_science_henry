# ðŸŽ“ Clase 11: Consulta y Repaso Pre-Proyecto Final

**Fecha**: Lunes prÃ³ximo  
**DuraciÃ³n**: 2 horas  
**Modalidad**: Consulta abierta + Repaso estructurado

---

## ðŸŽ¯ Objetivos de esta Clase

1. âœ… **Repasar** conceptos clave de las 10 clases anteriores
2. âœ… **Resolver dudas** especÃ­ficas antes del proyecto final
3. âœ… **Proporcionar guÃ­as** para abordar el proyecto exitosamente
4. âœ… **Compartir mejores prÃ¡cticas** y errores comunes a evitar
5. âœ… **Q&A abierto** sobre cualquier tema del curso

**Esta clase NO introduce contenido nuevo**. Todo es repaso y consulta.

---

## ðŸ“š Material Preparado

### En `notebooks/`:

#### **ðŸ““ RESUMEN_TEMAS_CURSADA.ipynb** â­
Notebook completo de repaso con:
- Resumen de los 4 mÃ³dulos del curso
- FÃ³rmulas y conceptos clave por clase
- CÃ³digo esencial (cheat sheets)
- Templates listos para usar
- Errores comunes y cÃ³mo evitarlos
- GuÃ­a paso a paso para el proyecto final

**CÃ³mo usar**: Ãbrelo en Jupyter y sÃ­guelo durante la clase.

---

### En `data/`:

#### **ðŸ“Š RESUMEN_COMPLETO_CURSADA.md** â­
Documento maestro con:
- EstadÃ­sticas de lo aprendido (25+ algoritmos, 20+ mÃ©tricas)
- Resumen detallado de cada clase
- Checklist de habilidades adquiridas
- GuÃ­a completa para el proyecto final
- Consejos para presentaciÃ³n y evaluaciÃ³n

**CÃ³mo usar**: Documento de referencia durante el proyecto.

---

#### **ðŸ“‹ DATASETS_Y_CASOS.md**
CatÃ¡logo completo de todos los datasets:
- 20 datasets del curso descritos
- Tabla comparativa (filas, tipo, dificultad)
- Casos de uso por algoritmo
- Datasets externos recomendados (Kaggle, UCI)
- Template de propuesta de proyecto

**CÃ³mo usar**: Para elegir dataset del proyecto o inspirarte.

---

## ðŸ“‹ Agenda de la Clase

### Parte 1: Repaso Estructurado (60 min)

**MÃ³dulo 1: Fundamentos** (15 min)
- RegresiÃ³n y clasificaciÃ³n bÃ¡sica
- MÃ©tricas fundamentales
- Preprocesamiento

**MÃ³dulo 2: Avanzado** (15 min)
- Ensambles (Bagging, Boosting)
- OptimizaciÃ³n (Grid Search, Optuna)

**MÃ³dulo 3: No Supervisado** (15 min)
- Clustering (K-Means, DBSCAN)
- Recomendaciones

**MÃ³dulo 4: Series Temporales y DL** (15 min)
- ARIMA, Prophet
- LSTM en PyTorch
- Caso VIX: Lecciones aprendidas

### Parte 2: Proyecto Final (30 min)

- Estructura sugerida
- Checklist de entregables
- Criterios de evaluaciÃ³n
- Errores comunes a evitar
- Datasets recomendados

### Parte 3: Q&A Abierto (30 min)

- Dudas especÃ­ficas
- Problemas tÃ©cnicos
- DiscusiÃ³n de enfoques
- RevisiÃ³n de propuestas (si traen)

---

## ðŸŽ¯ PROYECTO FINAL: Requisitos MÃ­nimos

### **Estructura Obligatoria:**

1. **ðŸ““ Notebooks**:
   - `01_eda.ipynb` - AnÃ¡lisis exploratorio
   - `02_preprocessing.ipynb` - Limpieza y transformaciones
   - `03_modeling.ipynb` - Al menos 3 modelos diferentes
   - `04_evaluation.ipynb` - MÃ©tricas y comparaciÃ³n

2. **ðŸ“„ DocumentaciÃ³n**:
   - `README.md` - DescripciÃ³n, instalaciÃ³n, ejecuciÃ³n
   - `requirements.txt` - Dependencias

3. **ðŸ“Š Datos**:
   - Dataset(s) en carpeta `data/`
   - Documentar origen y licencia

---

### **Criterios de EvaluaciÃ³n:**

| Aspecto | Peso | QuÃ© se evalÃºa |
|---------|------|---------------|
| **DefiniciÃ³n del problema** | 10% | Claridad, relevancia de negocio |
| **EDA** | 20% | Profundidad, visualizaciones, insights |
| **Preprocesamiento** | 10% | JustificaciÃ³n de decisiones |
| **Modelado** | 25% | Al menos 3 modelos, baseline incluido |
| **EvaluaciÃ³n** | 15% | MÃ©tricas apropiadas, validaciÃ³n cruzada |
| **OptimizaciÃ³n** | 10% | Tuning de hyperparÃ¡metros |
| **Interpretabilidad** | 5% | Feature importance mÃ­nimo |
| **Conclusiones** | 10% | Recomendaciones de negocio |
| **DocumentaciÃ³n** | 5% | README, comentarios, reproducibilidad |

**Total**: 110% (hay 10% de bonus en interpretabilidad)

---

## âœ… CHECKLIST PRE-ENTREGA

Verifica que tu proyecto cumple:

### CÃ³digo
- [ ] Todos los notebooks ejecutan sin errores
- [ ] Seeds fijas (reproducibilidad)
- [ ] Imports al inicio de cada notebook
- [ ] CÃ³digo comentado (especialmente decisiones importantes)
- [ ] No hay "magic numbers" (usar constantes)

### Datos
- [ ] Train/test split documentado
- [ ] No hay data leakage (normalizaciÃ³n despuÃ©s de split)
- [ ] Faltantes manejados y justificado cÃ³mo
- [ ] Outliers analizados (eliminar o no, justificado)

### Modelos
- [ ] MÃ­nimo 3 modelos diferentes
- [ ] Baseline simple incluido (Linear Regression o Persistencia)
- [ ] ValidaciÃ³n cruzada (K-Fold con kâ‰¥5)
- [ ] ComparaciÃ³n de modelos en tabla

### MÃ©tricas
- [ ] MÃ©tricas apropiadas al problema
- [ ] Train Y test scores reportados
- [ ] ComparaciÃ³n con baseline
- [ ] InterpretaciÃ³n de resultados (no solo nÃºmeros)

### Visualizaciones
- [ ] GrÃ¡ficos con tÃ­tulos y labels
- [ ] Distribuciones del target
- [ ] Correlaciones importantes
- [ ] Curva de aprendizaje (si aplica)
- [ ] Matriz de confusiÃ³n (si clasificaciÃ³n)

### DocumentaciÃ³n
- [ ] README.md con:
  - DescripciÃ³n del problema
  - Instrucciones de instalaciÃ³n
  - CÃ³mo ejecutar el cÃ³digo
  - Resultados principales
- [ ] Conclusiones de negocio (no solo tÃ©cnicas)
- [ ] Limitaciones reconocidas
- [ ] PrÃ³ximos pasos sugeridos

---

## ðŸ’¬ PREGUNTAS FRECUENTES

### **"Â¿Puedo usar un dataset del curso?"**

âœ… **SÃ­**, perfectamente vÃ¡lido. Sugerimos:
- RetailBoost (regresiÃ³n)
- Churn Bancario (clasificaciÃ³n)
- ShopSense (clustering + recomendaciones)
- CityScoot (series temporales)

Ventaja: Ya conoces los datos, puedes enfocarte en modelado.

---

### **"Â¿Debo usar Deep Learning?"**

âŒ **No es obligatorio**. Deep Learning es apropiado si:
- Tienes >10,000 observaciones
- El problema es muy complejo (no lineal)
- Tienes GPU disponible
- Quieres experimentar con PyTorch

âœ… **Para la mayorÃ­a de proyectos**: XGBoost/Random Forest es suficiente y a veces superior.

---

### **"Â¿CuÃ¡ntos modelos debo probar?"**

**MÃ­nimo**: 3 modelos diferentes + 1 baseline

**Ejemplos de combinaciones:**

**Para ClasificaciÃ³n:**
1. Baseline: Logistic Regression
2. Random Forest
3. XGBoost
4. SVM (opcional)

**Para RegresiÃ³n:**
1. Baseline: Linear Regression
2. Ridge/Lasso
3. Random Forest
4. XGBoost

**Para Series Temporales:**
1. Baseline: Persistencia (Å·_t = y_{t-1})
2. ARIMA/SARIMA
3. Prophet
4. XGBoost con lags
5. LSTM (opcional)

---

### **"Â¿CÃ³mo sÃ© si mi modelo es bueno?"**

**Compara con baseline:**
- Si no superas baseline â†’ modelo no estÃ¡ aprendiendo
- Mejora de 1-5% â†’ bueno
- Mejora de 5-15% â†’ muy bueno
- Mejora de 15%+ â†’ excelente (o posible data leakage, verificar)

**Compara con literatura:**
- Busca en Kaggle/papers problemas similares
- Ve quÃ© mÃ©tricas logran otros
- Tu modelo debe estar en el rango

**Ejemplo**:
- Titanic: Accuracy tÃ­pico = 78-82%
- Si logras 85% â†’ Excelente
- Si logras 95% â†’ Revisa data leakage

---

### **"Â¿CuÃ¡nto tiempo deberÃ­a tomar?"**

**EstimaciÃ³n realista:**

| Fase | DÃ­as | Horas |
|------|------|-------|
| SelecciÃ³n y EDA | 2-3 | 6-9h |
| Preprocesamiento | 1-2 | 3-6h |
| Modelado | 2-3 | 6-9h |
| OptimizaciÃ³n | 1-2 | 3-6h |
| Interpretabilidad | 1 | 3h |
| DocumentaciÃ³n | 1 | 3h |
| **TOTAL** | **8-12 dÃ­as** | **24-36h** |

**RecomendaciÃ³n**: Empieza YA, no esperes al Ãºltimo dÃ­a.

---

## ðŸ“… CRONOGRAMA SUGERIDO

**Hoy (despuÃ©s de esta clase)**:
- Elegir dataset
- Definir problema
- Crear estructura de carpetas

**Esta semana (Lun-Vie)**:
- EDA completo
- Baseline implementado
- Preprocesamiento terminado

**PrÃ³xima semana**:
- Modelos avanzados
- OptimizaciÃ³n
- EvaluaciÃ³n

**3 dÃ­as antes de entrega**:
- Interpretabilidad
- Visualizaciones finales
- DocumentaciÃ³n

**1 dÃ­a antes**:
- RevisiÃ³n final
- CÃ³digo limpio
- README profesional

---

## ðŸ”— ENLACES ÃšTILES

### DocumentaciÃ³n del Curso
- [README Principal](../README.md)
- [QUICKSTART](../QUICKSTART.md)
- [ARCHITECTURE](../ARCHITECTURE.md)

### Material de Esta Clase
- [Notebook Resumen](./notebooks/RESUMEN_TEMAS_CURSADA.ipynb)
- [Resumen Completo Cursada](./data/RESUMEN_COMPLETO_CURSADA.md)
- [Datasets y Casos](./data/DATASETS_Y_CASOS.md)

### Clase 10 (Ejemplo de Proyecto Ejemplar)
- [Notebook VIX-LSTM](../clase_10_deep_learning/notebooks/homework_vix_lstm_completo_didactico.ipynb)
- [AnÃ¡lisis Completo](../clase_10_deep_learning/docs/ANALISIS_COMPLETO_VIX_LSTM.md)
- [Lecturas Recomendadas](../clase_10_deep_learning/docs/LECTURAS_RECOMENDADAS_VIX_LSTM.md)

---

## ðŸ’¡ MENSAJE FINAL

### Has aprendido:
- âœ… 25+ algoritmos de ML/DL
- âœ… 20+ mÃ©tricas de evaluaciÃ³n
- âœ… Scikit-learn, XGBoost, PyTorch
- âœ… Preprocesamiento, EDA, feature engineering
- âœ… ValidaciÃ³n, optimizaciÃ³n, interpretabilidad

### Ahora puedes:
- âœ… Resolver problemas reales de Data Science
- âœ… Construir pipelines completos de ML
- âœ… Elegir el algoritmo apropiado para cada problema
- âœ… Evaluar e interpretar resultados correctamente

### Para el proyecto:
- ðŸŽ¯ Empieza simple (baseline)
- ðŸŽ¯ Documenta decisiones
- ðŸŽ¯ Compara modelos
- ðŸŽ¯ Piensa en negocio (no solo tÃ©cnica)

---

## ðŸ“§ CONTACTO

**Instructor**: Mariano Gobea  
**Email**: mariano.gobea@mercadolibre.com  
**Consultas**: Durante la clase del lunes o por email

---

## ðŸŽ‰ Â¡Ã‰XITO EN TU PROYECTO FINAL!

**Nos vemos el lunes para resolver tus dudas.** ðŸš€

---

**Ãšltima actualizaciÃ³n**: Febrero 16, 2026
