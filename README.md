# ğŸ“ Curso de Data Science y Machine Learning - Henry
## FormaciÃ³n Completa: Del ML ClÃ¡sico al Deep Learning

**DuraciÃ³n**: 11 clases (10 teÃ³rico-prÃ¡cticas + 1 consulta)  
**Nivel**: Principiante a Intermedio  
**Ãšltima actualizaciÃ³n**: Febrero 2026

---

## ğŸ“š Contenido del Curso

### **MÃ³dulo 1: Fundamentos de Machine Learning**

#### **ğŸ“Œ Clase 01: IntroducciÃ³n al Machine Learning**
- Conceptos fundamentales: IA, ML, DL, GenAI
- Tipos de aprendizaje (supervisado, no supervisado, por refuerzo)
- Pipeline completo de un proyecto de ML
- Elementos de un modelo: features, target, parÃ¡metros, hiperparÃ¡metros
- Underfitting vs Overfitting
- Feature engineering bÃ¡sico
- **Caso prÃ¡ctico**: EDA de clientes RetailBoost
- **Datasets**: `retailboost_customers.csv`

#### **ğŸ“Œ Clase 02: RegresiÃ³n**
- RegresiÃ³n lineal simple y mÃºltiple
- MÃ©tricas: MSE, RMSE, MAE, RÂ², MAPE
- RegularizaciÃ³n: Ridge (L2), Lasso (L1), ElasticNet
- RegresiÃ³n polinÃ³mica
- ValidaciÃ³n cruzada (K-Fold)
- AnÃ¡lisis de residuos
- **Caso prÃ¡ctico**: PredicciÃ³n de valor de clientes RetailBoost
- **Datasets**: `retailboost_customers_regression.csv`

#### **ğŸ“Œ Clase 03: RegresiÃ³n LogÃ­stica**
- Fundamentos y funciÃ³n sigmoide
- ClasificaciÃ³n binaria y multiclase (OvR, OvO, Softmax)
- InterpretaciÃ³n: odds, log-odds, odds ratio
- MÃ©tricas de clasificaciÃ³n (Accuracy, Precision, Recall, F1-Score, ROC-AUC)
- Log-loss y regularizaciÃ³n
- **Caso prÃ¡ctico**: PredicciÃ³n de churn bancario
- **Datasets**: `Churn_Modelling.csv`

#### **ğŸ“Œ Clase 04: Modelos de ClasificaciÃ³n y MÃ©tricas**
- K-Nearest Neighbors (KNN)
- Decision Trees (Ã¡rboles de decisiÃ³n)
- Random Forest
- Support Vector Machines (SVM) con kernels
- MÃ©tricas avanzadas para clasificaciÃ³n
- Manejo de clases desbalanceadas
- **Caso prÃ¡ctico**: ClasificaciÃ³n de leads fintech
- **Datasets**: `martech_homework_dataset_fixed.csv`

---

### **MÃ³dulo 2: Modelos Avanzados y OptimizaciÃ³n**

#### **ğŸ“Œ Clase 05: Modelos de Ensamble**
- Trade-off sesgo-varianza
- Bagging: Random Forest en profundidad
- Boosting: Gradient Boosting, XGBoost, LightGBM, CatBoost
- Stacking y Blending
- Voting ensembles
- Bootstrap y submuestreo de caracterÃ­sticas
- **Caso prÃ¡ctico**: ComparaciÃ³n de algoritmos de boosting

#### **ğŸ“Œ Clase 06: OptimizaciÃ³n de Modelos**
- Overfitting vs Underfitting
- Grid Search y Random Search
- BÃºsqueda bayesiana (Optuna)
- Feature selection y feature importance
- RegularizaciÃ³n avanzada (L1, L2, ElasticNet)
- Ajuste fino de Gradient Boosting
- **Caso prÃ¡ctico**: OptimizaciÃ³n de hyperparÃ¡metros con Optuna

---

### **MÃ³dulo 3: Aprendizaje No Supervisado**

#### **ğŸ“Œ Clase 07: Clustering y SegmentaciÃ³n**
- Algoritmos: K-Means, DBSCAN, Hierarchical
- MÃ©tricas: Elbow method, Silhouette, Davies-Bouldin
- ReducciÃ³n de dimensionalidad: PCA, t-SNE
- AnÃ¡lisis RFM (Recency, Frequency, Monetary)
- **Caso prÃ¡ctico**: SegmentaciÃ³n de clientes ShopSense Retail
- **Datasets**: `Mall_Customers.csv`, `shopsense_customers_clean.csv`

#### **ğŸ“Œ Clase 08: Sistemas de RecomendaciÃ³n**
- Filtrado colaborativo (user-based, item-based)
- Filtrado basado en contenido
- Modelos hÃ­bridos
- MÃ©tricas: Precision@K, Recall@K, NDCG@K
- LibrerÃ­a Surprise
- **Caso prÃ¡ctico**: Sistema de recomendaciÃ³n ShopSense
- **Datasets**: `users_clean.csv`, `items.csv`, `interactions.csv`

---

### **MÃ³dulo 4: Series Temporales y Deep Learning**

#### **ğŸ“Œ Clase 09: AnÃ¡lisis de Series Temporales**
- Componentes: tendencia, estacionalidad, ruido
- Estacionariedad y pruebas estadÃ­sticas (ADF)
- AutocorrelaciÃ³n: ACF, PACF
- Modelos clÃ¡sicos: ARIMA, SARIMA
- Prophet (Facebook)
- Forecasting como problema supervisado (Random Forest, XGBoost)
- ValidaciÃ³n temporal y prevenciÃ³n de data leakage
- **Caso prÃ¡ctico**: PredicciÃ³n de demanda diaria CityScoot
- **Datasets**: `cityscoot_daily_rides.csv`

#### **ğŸ“Œ Clase 10: IntroducciÃ³n al Deep Learning** â­
- Fundamentos de redes neuronales
- PerceptrÃ³n, activaciones, backpropagation
- PyTorch: Tensors, Autograd, Dataset, DataLoader, nn.Module
- Redes densas (feedforward) para clasificaciÃ³n
- LSTM para series temporales
- RegularizaciÃ³n: dropout, early stopping
- Optimizadores: Adam, SGD
- **Casos prÃ¡cticos**:
  - FinShield: DetecciÃ³n de fraude con redes densas
  - EconoTrend: PredicciÃ³n del VIX con LSTM
- **Datasets**: `finshield_transactions_clean.csv`, `econotrend_vix_sim.csv`
- **â­ Material extra**: DocumentaciÃ³n extensa en `docs/` con anÃ¡lisis completo, lecturas recomendadas, y verificaciones

#### **ğŸ“Œ Clase 11: Consulta y Repaso**
- Repaso de conceptos clave de todo el curso
- ResoluciÃ³n de dudas
- PreparaciÃ³n para proyecto final
- Q&A abierto

---

## ğŸ—‚ï¸ Estructura de Directorios

```
data_science_henry/
â”œâ”€â”€ clase_01_introduccion_ml/
â”‚   â”œâ”€â”€ notebooks/          # 3 notebooks (EDA RetailBoost)
â”‚   â”œâ”€â”€ scripts/            # 2 scripts (preprocessing, data_loader)
â”‚   â”œâ”€â”€ docs/               # 3 documentos
â”‚   â”œâ”€â”€ data/               # 5 datasets
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ clase_02_regresion/
â”‚   â”œâ”€â”€ notebooks/          # 3 notebooks (RegresiÃ³n RetailBoost)
â”‚   â”œâ”€â”€ scripts/            # 1 script (get_metrics)
â”‚   â”œâ”€â”€ docs/               # 3 documentos
â”‚   â”œâ”€â”€ data/               # 1 dataset
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ clase_03_regresion_logistica/
â”‚   â”œâ”€â”€ notebooks/          # 2 notebooks (Churn prediction)
â”‚   â”œâ”€â”€ docs/               # 4 documentos
â”‚   â”œâ”€â”€ data/               # 1 dataset
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ clase_04_clasificacion_metricas/
â”‚   â”œâ”€â”€ notebooks/          # 1 notebook (Leads fintech)
â”‚   â”œâ”€â”€ docs/               # 2 documentos
â”‚   â””â”€â”€ data/               # 1 dataset
â”œâ”€â”€ clase_05_modelos_ensamble/
â”‚   â”œâ”€â”€ notebooks/          # 1 notebook
â”‚   â””â”€â”€ docs/               # 2 documentos
â”œâ”€â”€ clase_06_optimizacion_modelos/
â”‚   â”œâ”€â”€ notebooks/          # 3 notebooks (+ catboost_info/)
â”‚   â””â”€â”€ docs/               # 2 documentos
â”œâ”€â”€ clase_07_aprendizaje_no_supervisado_i/
â”‚   â”œâ”€â”€ notebooks/          # 2 notebooks (Clustering Mall/ShopSense)
â”‚   â”œâ”€â”€ docs/               # 2 documentos
â”‚   â””â”€â”€ data/               # 3 datasets
â”œâ”€â”€ clase_08_aprendizaje_no_supervisado_ii/
â”‚   â”œâ”€â”€ notebooks/          # 2 notebooks (Recomendaciones ShopSense)
â”‚   â”œâ”€â”€ docs/               # 2 documentos
â”‚   â””â”€â”€ data/               # 4 datasets
â”œâ”€â”€ clase_09_series_temporales/
â”‚   â”œâ”€â”€ notebooks/          # 2 notebooks (CityScoot forecasting)
â”‚   â”œâ”€â”€ docs/               # 4 documentos
â”‚   â””â”€â”€ data/               # 1 dataset
â”œâ”€â”€ clase_10_deep_learning/ â­
â”‚   â”œâ”€â”€ notebooks/          # 4 notebooks + 2 markdown guÃ­as
â”‚   â”œâ”€â”€ docs/               # 7 documentos (anÃ¡lisis exhaustivo)
â”‚   â”œâ”€â”€ data/               # 2 datasets
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ clase_11_consulta/
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ utils/                  # MÃ³dulo de utilidades compartidas
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_processing.py
â”‚   â”œâ”€â”€ visualization.py
â”‚   â””â”€â”€ model_evaluation.py
â”œâ”€â”€ pyproject.toml          # GestiÃ³n de dependencias con Poetry
â”œâ”€â”€ requirements.txt        # Dependencias (backup para pip)
â”œâ”€â”€ README.md               # Este archivo
â”œâ”€â”€ QUICKSTART.md           # GuÃ­a de inicio rÃ¡pido
â”œâ”€â”€ ARCHITECTURE.md         # Arquitectura del proyecto
â”œâ”€â”€ CONTRIBUTING.md         # GuÃ­a de contribuciÃ³n
â”œâ”€â”€ LICENSE                 # Licencia MIT
â””â”€â”€ Makefile                # Comandos automatizados
```

**Nota**: Las carpetas `scripts/` vacÃ­as fueron eliminadas. Solo `clase_01` y `clase_02` mantienen scripts Ãºtiles.

---

## ğŸ“Š EstadÃ­sticas del Proyecto

- **Total de notebooks**: 23
- **Total de datasets**: 20
- **Total de documentos**: 31
- **Scripts Ãºtiles**: 3 (en clase_01 y clase_02)
- **Clases con README**: 5 de 11

---

## ğŸš€ InstalaciÃ³n RÃ¡pida

### OpciÃ³n 1: Poetry (Recomendado)

```bash
# 1. Instalar Poetry
curl -sSL https://install.python-poetry.org | python3 -

# 2. Navegar al proyecto
cd data_science_henry

# 3. Instalar dependencias
poetry install

# 4. Activar entorno
poetry shell

# 5. Lanzar Jupyter
jupyter lab
```

### OpciÃ³n 2: pip + venv

```bash
# 1. Crear entorno virtual
python -m venv .venv

# 2. Activar entorno
source .venv/bin/activate  # Mac/Linux
# o
.venv\Scripts\activate     # Windows

# 3. Instalar dependencias
pip install -r requirements.txt

# 4. Lanzar Jupyter
jupyter lab
```

---

## ğŸ› ï¸ TecnologÃ­as y LibrerÃ­as

### **Core Data Science**
- **NumPy** (1.26.4): Operaciones numÃ©ricas
- **Pandas** (2.3.3): ManipulaciÃ³n de datos
- **Matplotlib/Seaborn**: VisualizaciÃ³n
- **SciPy**: Funciones cientÃ­ficas

### **Machine Learning**
- **Scikit-learn**: Algoritmos clÃ¡sicos de ML
- **XGBoost**: Gradient Boosting optimizado
- **LightGBM**: Gradient Boosting rÃ¡pido
- **CatBoost**: GB para variables categÃ³ricas
- **Optuna**: OptimizaciÃ³n bayesiana

### **Deep Learning**
- **PyTorch** (2.2.2): Framework de DL
- **TorchVision**: VisiÃ³n por computadora

### **Series Temporales**
- **Statsmodels**: Modelos estadÃ­sticos (ARIMA, SARIMA)
- **Prophet**: Forecasting (Facebook)

### **Interpretabilidad**
- **SHAP**: ExplicaciÃ³n de modelos
- **LIME**: Interpretabilidad local
- **Yellowbrick**: VisualizaciÃ³n para ML

### **Entorno**
- **JupyterLab**: IDE para notebooks
- **Poetry**: GestiÃ³n de dependencias

---

## ğŸ“– GuÃ­as de Uso

### Para Estudiantes

1. **Inicio**: Lee `QUICKSTART.md`
2. **Orden**: Sigue las clases secuencialmente (01 â†’ 11)
3. **PrÃ¡ctica**: Ejecuta cada notebook celda por celda
4. **ExperimentaciÃ³n**: Modifica cÃ³digo y parÃ¡metros
5. **Consulta**: Usa clase_11 para dudas finales

### Para Instructores

1. **Estructura**: Ver `ARCHITECTURE.md` para detalles tÃ©cnicos
2. **Material**: Cada clase tiene docs/ con presentaciones y guÃ­as
3. **Scripts**: clase_01 y clase_02 tienen scripts reutilizables
4. **EvaluaciÃ³n**: Homeworks en notebooks claramente etiquetados

---

## ğŸ¯ Casos PrÃ¡cticos por Dominio

| Dominio | Clase | Caso | Dataset |
|---------|-------|------|---------|
| **Retail** | 01-02 | RetailBoost: EDA y regresiÃ³n | retailboost_customers.csv |
| **Finanzas** | 03 | Churn bancario | Churn_Modelling.csv |
| **Marketing** | 04 | ClasificaciÃ³n de leads fintech | martech_homework.csv |
| **Retail** | 07-08 | ShopSense: clustering y recomendaciones | shopsense_customers.csv |
| **Movilidad** | 09 | CityScoot: forecasting de demanda | cityscoot_daily_rides.csv |
| **Finanzas** | 10 | EconoTrend: predicciÃ³n del VIX con LSTM | econotrend_vix_sim.csv |
| **Fintech** | 10 | FinShield: detecciÃ³n de fraude con DL | finshield_transactions.csv |

---

## ğŸ”¥ Highlights del Curso

### **Clase 10: Deep Learning** â­ **[MÃS COMPLETA]**

La clase de Deep Learning incluye material pedagÃ³gico extenso:

- **4 notebooks** (2 casos prÃ¡cticos + 2 guÃ­as)
- **7 documentos** de anÃ¡lisis y referencias
- **Material extra**:
  - `ANALISIS_COMPLETO_VIX_LSTM.md`: AnÃ¡lisis exhaustivo de resultados
  - `LECTURAS_RECOMENDADAS_VIX_LSTM.md`: 30+ recursos organizados por nivel
  - `VERIFICACION_AFIRMACIONES_DATOS.md`: 87 afirmaciones verificadas
  - `LECTURAS_COMPLETAS_POR_CELDA.md`: GuÃ­a para instructores
  - `CORRECCIONES.md`: DocumentaciÃ³n de soluciones a problemas comunes

**Notebooks destacados:**
1. `homework_vix_lstm_completo_didactico.ipynb` (3,066 lÃ­neas, 1.6 MB)
   - Tutorial completo de LSTM en PyTorch
   - 100% didÃ¡ctico con explicaciones exhaustivas
   - Predice el Ã­ndice VIX (volatilidad del mercado)
   - Incluye WIKIs, visualizaciones, y lecturas recomendadas

2. `finshield_pytorch_dense_Edited_Leo2.ipynb`
   - DetecciÃ³n de fraude transaccional
   - Redes densas en PyTorch
   - Pipeline completo de clasificaciÃ³n

---

## ğŸ“Š Recursos Adicionales

### LibrerÃ­as Principales

**Data Processing**:
- NumPy, Pandas, SciPy

**VisualizaciÃ³n**:
- Matplotlib, Seaborn, Plotly, Yellowbrick

**Machine Learning**:
- Scikit-learn, XGBoost, LightGBM, CatBoost, Imbalanced-learn, Optuna

**Deep Learning**:
- PyTorch, TorchVision

**Series Temporales**:
- Statsmodels, Prophet

### Libros Recomendados

- **"Hands-On Machine Learning with Scikit-Learn, Keras & TensorFlow"** - AurÃ©lien GÃ©ron
- **"Python for Data Analysis"** - Wes McKinney
- **"Deep Learning"** - Ian Goodfellow, Yoshua Bengio, Aaron Courville
- **"Forecasting: Principles and Practice"** - Rob J Hyndman & George Athanasopoulos (online gratis)

### Datasets PÃºblicos

- [Kaggle](https://www.kaggle.com/datasets)
- [UCI ML Repository](https://archive.ics.uci.edu/ml/)
- [Google Dataset Search](https://datasetsearch.research.google.com/)

---

## ğŸ“ Proyecto Final

El curso culmina con un proyecto integrador que debe incluir:

1. **DefiniciÃ³n del problema** de negocio
2. **EDA exhaustivo** con visualizaciones
3. **Preprocesamiento** y feature engineering
4. **Modelado** con al menos 3 algoritmos diferentes
5. **OptimizaciÃ³n** de hiperparÃ¡metros
6. **EvaluaciÃ³n** con mÃ©tricas apropiadas
7. **Interpretabilidad** (SHAP/LIME)
8. **Conclusiones** y recomendaciones de negocio

**Consulta previa al proyecto**: Clase 11 (prÃ³ximo lunes)

---

## ğŸ¤ ContribuciÃ³n

Este es un proyecto educativo activo. Contribuciones bienvenidas:

1. Abre un **issue** para reportar errores
2. PropÃ³n **mejoras** mediante pull requests
3. Comparte tus **notebooks** y proyectos

Ver `CONTRIBUTING.md` para mÃ¡s detalles.

---

## ğŸ“§ Contacto

**Instructor**: Mariano Gobea  
**Email**: mariano.gobea@mercadolibre.com / gobeamariano@gmail.com 
**Consultas**: Usa el sistema de issues del repositorio

---

## ğŸ“œ Licencia

Este proyecto estÃ¡ bajo la **Licencia MIT**. Ver el archivo `LICENSE` para mÃ¡s detalles.

---

**Ãšltima actualizaciÃ³n**: Febrero 2026  
**VersiÃ³n del curso**: 1.0.0

ğŸš€ **Â¿Listo para comenzar? â†’ Abre `QUICKSTART.md`**
